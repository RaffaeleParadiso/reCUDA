{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pycuda\n",
    "import pycuda\n",
    "!nvcc --version  # Check CUDA version\n",
    "!gcc --version # Check gcc version\n",
    "!nvidia-smi # Check GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pycuda.driver as drv\n",
    "drv.init()\n",
    "drv.get_version()\n",
    "devn=drv.Device.count()\n",
    "print(\"N GPU \"+str(devn))\n",
    "devices = []\n",
    "for i in range(devn):\n",
    "  devices.append(drv.Device(i))\n",
    "for sp in devices:\n",
    "  print(\"GPU name: \"+str(sp.name))\n",
    "  print(\"Compute Capability = \"+str(sp.compute_capability()))\n",
    "  print(\"Total Memory = \"+str(sp.total_memory()/(2.**20))+' MBytes')\n",
    "  attr = sp.get_attributes()\n",
    "  print(attr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With DeviceData()\n",
    "from pycuda import autoinit\n",
    "from pycuda.tools import DeviceData\n",
    "specs = DeviceData()\n",
    "print ('Max threads per block = '+str(specs.max_threads))\n",
    "print ('Warp size             = '+str(specs.warp_size))\n",
    "print ('Warps per MP          = '+str(specs.warps_per_mp))\n",
    "print ('Thread Blocks per MP  = '+str(specs.thread_blocks_per_mp))\n",
    "print ('Registers             = '+str(specs.registers))\n",
    "print ('Shared memory         = '+str(specs.shared_memory))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example GPU in C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile VecAdd.cu\n",
    "# include <stdio.h>\n",
    "# include <cuda_runtime.h>\n",
    "// CUDA Kernel\n",
    "__global__ void vectorAdd(const float *A, const float *B, float *C, int numElements)\n",
    "{\n",
    "    int i = blockDim.x * blockIdx.x + threadIdx.x;\n",
    "    if (i < numElements)\n",
    "    {\n",
    "        C[i] = A[i] + B[i];\n",
    "    }\n",
    "}\n",
    "\n",
    "/**\n",
    " * Host main routine\n",
    " */\n",
    "int main(void)\n",
    "{\n",
    "    int numElements = 15;\n",
    "    size_t size = numElements * sizeof(float);\n",
    "    printf(\"[Vector addition of %d elements]\\n\", numElements);\n",
    "\n",
    "    float a[numElements],b[numElements],c[numElements];\n",
    "    float *a_gpu,*b_gpu,*c_gpu;\n",
    "\n",
    "    cudaMalloc((void **)&a_gpu, size);\n",
    "    cudaMalloc((void **)&b_gpu, size);\n",
    "    cudaMalloc((void **)&c_gpu, size);\n",
    "\n",
    "    for (int i=0;i<numElements;++i ){\n",
    "\n",
    "        a[i] = i*i;\n",
    "        b[i] = i;\n",
    "\n",
    "    }\n",
    "    // Copy the host input vectors A and B in host memory to the device input vectors in\n",
    "    // device memory\n",
    "    printf(\"Copy input data from the host memory to the CUDA device\\n\");\n",
    "    cudaMemcpy(a_gpu, a, size, cudaMemcpyHostToDevice);\n",
    "    cudaMemcpy(b_gpu, b, size, cudaMemcpyHostToDevice);\n",
    "\n",
    "    // Launch the Vector Add CUDA Kernel\n",
    "    int threadsPerBlock = 256;\n",
    "    int blocksPerGrid =(numElements + threadsPerBlock - 1) / threadsPerBlock;\n",
    "    printf(\"CUDA kernel launch with %d blocks of %d threads\\n\", blocksPerGrid, threadsPerBlock);\n",
    "    vectorAdd<<<blocksPerGrid, threadsPerBlock>>>(a_gpu, b_gpu, c_gpu, numElements);\n",
    "\n",
    "    // Copy the device result vector in device memory to the host result vector\n",
    "    // in host memory.\n",
    "    printf(\"Copy output data from the CUDA device to the host memory\\n\");\n",
    "    cudaMemcpy(c, c_gpu, size, cudaMemcpyDeviceToHost);\n",
    "\n",
    "    for (int i=0;i<numElements;++i ){\n",
    "        printf(\"%f \\n\",c[i]);\n",
    "    }\n",
    "\n",
    "    // Free device global memory\n",
    "    cudaFree(a_gpu);\n",
    "    cudaFree(b_gpu);\n",
    "    cudaFree(c_gpu);\n",
    "\n",
    "    printf(\"Done\\n\");\n",
    "    return 0;\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvcc -o VecAdd VecAdd.cu\n",
    "!./VecAdd"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
